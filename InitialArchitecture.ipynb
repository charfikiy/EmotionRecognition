{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-09 19:08:15.426439\n",
      "length of training:  28708\n",
      "length of validation 3588\n",
      "length of testing 3588\n",
      "length of training:  28708\n",
      "length of validation 3588\n",
      "length of testing 3588\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "print(datetime.now())\n",
    "\n",
    "images_train = pandas.read_csv('./images_train.csv').values\n",
    "images_validate = pandas.read_csv('./images_validate.csv').values\n",
    "images_test = pandas.read_csv('./images_test.csv').values\n",
    "labels_train = pandas.read_csv('./labels_train.csv').values\n",
    "labels_validate = pandas.read_csv('./labels_validate.csv').values\n",
    "labels_test = pandas.read_csv('./labels_test.csv').values\n",
    "\n",
    "images_train = images_train.astype(numpy.float)\n",
    "images_validate = images_validate.astype(numpy.float)\n",
    "images_test = images_test.astype(numpy.float)\n",
    "\n",
    "images_train = numpy.multiply(images_train, 1.0 / 255.0)\n",
    "images_validate = numpy.multiply(images_validate, 1.0 / 255.0)\n",
    "images_test = numpy.multiply(images_test, 1.0 / 255.0)\n",
    "\n",
    "labels_train = labels_train.ravel()\n",
    "labels_validate = labels_validate.ravel()\n",
    "labels_test = labels_test.ravel()\n",
    "\n",
    "print(\"length of training: \", len(labels_train))\n",
    "print(\"length of validation\", len(labels_validate))\n",
    "print(\"length of testing\", len(labels_test))\n",
    "print(\"length of training: \", len(images_train))\n",
    "print(\"length of validation\", len(images_validate))\n",
    "print(\"length of testing\", len(images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "def one_hot(label, labels_unique):\n",
    "    index_offset = numpy.arange(label.shape[0]) * labels_unique\n",
    "    one_hot = numpy.zeros((label.shape[0], labels_unique))\n",
    "    one_hot.flat[index_offset + label.ravel()] = 1\n",
    "    labelset = one_hot.astype(numpy.uint8)  \n",
    "    return labelset\n",
    "\n",
    "labels_unique = 7\n",
    "labels_trainset = one_hot(labels_train, labels_unique)\n",
    "labels_validateset = one_hot(labels_validate, labels_unique)\n",
    "labels_testset = one_hot(labels_test, labels_unique)\n",
    "\n",
    "images_train = images_train.reshape([-1, 48, 48, 1])\n",
    "images_validate = images_validate.reshape([-1, 48, 48, 1])\n",
    "images_test = images_test.reshape([-1, 48, 48, 1])\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "network = input_data(shape=[None, 48, 48, 1])\n",
    "network = conv_2d(network, 64, 5, activation='relu')\n",
    "network = local_response_normalization(network)\n",
    "network = max_pool_2d(network, 3, strides=2)\n",
    "network = conv_2d(network, 64, 5, activation='relu')\n",
    "network = max_pool_2d(network, 3, strides=2)\n",
    "network = conv_2d(network, 128, 4, activation='relu')\n",
    "network = dropout(network, 0.3)\n",
    "network = fully_connected(network, 3072, activation='relu')\n",
    "network = fully_connected(network, 7, activation='softmax')\n",
    "network = regression(network,\n",
    "                                  optimizer='momentum',\n",
    "                                  loss='categorical_crossentropy')\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tflearn.DNN(network, checkpoint_path='emotion_recognition',\n",
    "                    max_checkpoints=1, tensorboard_verbose=2)    \n",
    "model.fit(\n",
    "            images_train, labels_trainset,\n",
    "            n_epoch=1,\n",
    "            batch_size=50,\n",
    "            shuffle=True,\n",
    "            show_metric=True,\n",
    "            snapshot_step=200,\n",
    "            snapshot_epoch=True,\n",
    "            run_id='emotion_recognition'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(images_train, labels_train)\n",
    "print('validation accuarcy: %0.4f%%' % (score[0] * 100))\n",
    "\n",
    "score = model.evaluate(images_validate, labels_validate)\n",
    "print('validation accuarcy: %0.4f%%' % (score[0] * 100))\n",
    "\n",
    "score = model.evaluate(images_test, labels_test)\n",
    "print('Test accuarcy: %0.4f%%' % (score[0] * 100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
